{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# IMPORTS\n",
    "import gzip\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "from random import seed\n",
    "from operator import itemgetter\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXACT ALGORITHM\n",
    "def exact_freq_items(thres, data):\n",
    "\n",
    "    # get start time of algorithm to calculate runtime later\n",
    "    start_time = time.time()\n",
    "\n",
    "    # create dict to store support of each item\n",
    "    support = dict()\n",
    "    # create a counter to measure dsize as we read thru data\n",
    "    dsize = 0\n",
    "\n",
    "    # open file and read transactions line by line\n",
    "    # increment dsize by 1 for each transaction\n",
    "    # loop thru transaction and increment support for each item present\n",
    "    with open(data, 'rt') as reader:\n",
    "        for transaction in reader:\n",
    "            \n",
    "            #increment dataset size counter\n",
    "            dsize += 1\n",
    "\n",
    "            # split string into the items it contains\n",
    "            # split() strips whitespace and newlines\n",
    "            elements = transaction.split()\n",
    "\n",
    "            # increment support for each item in transaction\n",
    "            # if item not in dict, add it then increment\n",
    "            # else just increment\n",
    "            for element in elements:\n",
    "                if element in support.keys():\n",
    "                    support[element] += 1\n",
    "                else:\n",
    "                    support[element] = 1\n",
    "    \n",
    "    # for each item in support, calculate frequency\n",
    "    # calculate by dividing support of item by dsize\n",
    "    # if frequency is greater than thres, add tuple to output\n",
    "    # tuple consists of item value followed by frequency\n",
    "    output = []\n",
    "    for element in support:\n",
    "        if support[element] / dsize >= thres:\n",
    "            output.append((int(element), support[element] / dsize))\n",
    "\n",
    "    # sort output by value of item in ascending order\n",
    "    # there can't be any ties\n",
    "    output = sorted(output, key=itemgetter(0))\n",
    "\n",
    "    # Sort output by frequency in descending order, ties broken by value of item \n",
    "    # python sorted() is \"stable\" so initial order is preserved during ties,\n",
    "    #   and original order is ascending by value of item\n",
    "    output = sorted(output, key= itemgetter(1), reverse=True) \n",
    "    \n",
    "    # get runtime\n",
    "    # multiply by 1000 to return value in ms and round to 3 decimals\n",
    "    final_time = round(1000 * (time.time() - start_time), 3)\n",
    "\n",
    "    # print size of dataset & runtime\n",
    "    #print(\"Size of dataset: \" + str(dsize))\n",
    "    #print(\"Runtime --- %s ms ---\" % final_time)\n",
    "\n",
    "    # return tuple of items and their frequencies\n",
    "    return output, final_time, dsize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run exact algorithm on webdocs dataset, ascribe id = 1\n",
    "# store output, runtime, and dataset size\n",
    "\n",
    "output1, runtime1, dsize1 = exact_freq_items(0, \"./data/webdocs.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run exact algorithm on kosarak dataset, ascribe id = 2\n",
    "# store output, runtime, and dataset size\n",
    "\n",
    "output2, runtime2, dsize2 = exact_freq_items(0, \"./data/kosarak.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run exact algorithm on accidents dataset, ascribe id = 3\n",
    "# store output, runtime, and dataset size\n",
    "\n",
    "output3, runtime3, dsize3 = exact_freq_items(0, \"./data/accidents.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "\n",
    "x1 = []\n",
    "y1 = []\n",
    "\n",
    "x2 = []\n",
    "y2 = []\n",
    "\n",
    "x3 = []\n",
    "y3 = []\n",
    "\n",
    "size1 = len(output1)\n",
    "# x1.append(1.0)\n",
    "# y1.append(0.0)\n",
    "counter = 1\n",
    "for freq in output1:\n",
    "    x1.append(freq[1])\n",
    "    y1.append(counter/size1)\n",
    "    counter += 1\n",
    "\n",
    "size2 = len(output2)\n",
    "# x2.append(1.0)\n",
    "# y2.append(0.0)\n",
    "counter = 1\n",
    "for freq in output2:\n",
    "    x2.append(freq[1])\n",
    "    y2.append(counter/size2)\n",
    "    counter += 1\n",
    "\n",
    "size3 = len(output3)\n",
    "# x3.append(1.0)\n",
    "# y3.append(0.0)\n",
    "counter = 1\n",
    "for freq in output3:\n",
    "    x3.append(freq[1])\n",
    "    y3.append(counter/size3)\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "plt.plot(x1,y1, label=\"Webdocs\", linestyle=\"-\")\n",
    "plt.plot(x2,y2, label=\"Kosarak\", linestyle=\"--\")\n",
    "plt.plot(x3,y3, label=\"accidents\", linestyle=\"-.\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling algorithm\n",
    "\n",
    "def sample_freq_items(ssize, dsize, delta, thres, data):\n",
    "    \n",
    "    seed(1998)\n",
    "\n",
    "    # get start time of algorithm to calculate runtime later\n",
    "    start_time = time.time()\n",
    "\n",
    "    samples = random.sample(range(dsize),k=ssize)\n",
    "    samples.sort()\n",
    "\n",
    "    support = dict()\n",
    "    next = samples.pop(0)\n",
    "    current = 0\n",
    "    max_t = 0\n",
    "    with open(data, 'rt') as reader:\n",
    "        for transaction in reader:\n",
    "            if current == next:\n",
    "                elements = transaction.split()\n",
    "\n",
    "                if len(elements) > max_t:\n",
    "                    max_t = len(elements)\n",
    "\n",
    "                for element in elements:\n",
    "                    if element in support:\n",
    "                        support[element] += 1\n",
    "                    else:\n",
    "                        support[element] = 1\n",
    "\n",
    "                next = samples.pop(0)\n",
    "                if len(samples) == 0:\n",
    "                    break\n",
    "\n",
    "            current += 1\n",
    "\n",
    "    ds = math.floor(math.log(max_t,2) + 1)\n",
    "    eps = math.sqrt(2*(ds + math.log(1/delta)) / ssize)\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for element in support:\n",
    "        if support[element] / ssize >= thres - eps/2:\n",
    "            output.append((int(element), support[element] / ssize))\n",
    "\n",
    "    # sort output by value of item in ascending order\n",
    "    # there can't be any ties\n",
    "    output = sorted(output, key=itemgetter(0))\n",
    "\n",
    "    # sort output by frequency in descending order, ties broken by value of item \n",
    "    # python sorted() is \"stable\" so order from intitial sort is preserved during ties,\n",
    "    #   and that order is ascending by value of item\n",
    "    output = sorted(output, key= itemgetter(1), reverse=True)\n",
    "\n",
    "    # get runtime\n",
    "    # multiply by 1000 to return value in ms and round to 3 decimals\n",
    "    runtime = round(1000 * (time.time() - start_time), 3)\n",
    "\n",
    "    # print runtime\n",
    "    #print(\"Runtime --- %s ms ---\" % runtime)\n",
    "\n",
    "    return runtime, eps, output\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dsize1 = 3384164\n",
    "runtime,eps,output = sample_freq_items(2000, dsize1, 0.1, 0.5,\"./data/webdocs.txt\")\n",
    "print(eps)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dsize2 = 2970006\n",
    "runtime,eps,output = sample_freq_items(2000, dsize2, 0.1, 0.3,\"./data/kosarak.txt\")\n",
    "print(eps)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dsize3 = 3401830\n",
    "\n",
    "thres = 0.8\n",
    "ssizes = [100,1000,10000,100000]\n",
    "\n",
    "max_runs = []\n",
    "min_runs = []\n",
    "avg_runs = []\n",
    "max_eps_runs = []\n",
    "\n",
    "max_err_runs = []\n",
    "min_err_runs = []\n",
    "avg_err_runs = []\n",
    "\n",
    "\n",
    "for ssize in ssizes:\n",
    "    runtimes = []\n",
    "    epss = []\n",
    "    max_outputs = []\n",
    "    min_outputs = []\n",
    "    avg_outputs = []\n",
    "\n",
    "    for run in range(0,5):\n",
    "        runtime,eps,output = sample_freq_items(ssize, dsize3, 0.1, thres,\"./data/accidents.txt\")\n",
    "        runtimes.append(runtime)\n",
    "        epss.append(eps)\n",
    "        outputs = [item[1] for item in output]\n",
    "        max_outputs.append(outputs.copy())\n",
    "        min_outputs.append(outputs.copy())\n",
    "        avg_outputs.append(outputs.copy())\n",
    "\n",
    "\n",
    "    max_runs.append(max(runtimes))\n",
    "    min_runs.append(min(runtimes))\n",
    "    avg_runs.append(mean(runtimes))\n",
    "    max_eps_runs.append(max(epss))\n",
    "\n",
    "    max_err_runs.append(max_outputs)\n",
    "    min_err_runs.append(min_outputs)\n",
    "    avg_err_runs.append(avg_outputs)\n",
    "    \n",
    "#exact runs\n",
    "output, runtime_eps, dsize = exact_freq_items(thres, \"./data/accidents.txt\")\n",
    "output_eps2, runtime_eps2, dsize_eps2 = exact_freq_items(thres-max_eps_runs[0], \"./data/accidents.txt\")\n",
    "\n",
    "for i in range(0,4):\n",
    "    for j in range(0,5):\n",
    "        \n",
    "        for k in range(0, len(max_err_runs[i][j])):\n",
    "            max_err_runs[i][j][k] = abs(max_err_runs[i][j][k] - output_eps2[k][1])\n",
    "            min_err_runs[i][j][k] = abs(min_err_runs[i][j][k] - output_eps2[k][1])\n",
    "            avg_err_runs[i][j][k] =abs(avg_err_runs[i][j][k] - output_eps2[k][1])\n",
    "\n",
    "        max_err_runs[i][j] = max(max_err_runs[i][j])\n",
    "        min_err_runs[i][j] = min(min_err_runs[i][j])\n",
    "        avg_err_runs[i][j] = mean(avg_err_runs[i][j])\n",
    "    max_err_runs[i] = max(max_err_runs[i])\n",
    "    min_err_runs[i] = min(min_err_runs[i])\n",
    "    avg_err_runs[i] = mean(avg_err_runs[i])\n",
    "        \n",
    "# Plot the lines for the runtimes of the sampling algorithm\n",
    "plt.plot(ssizes, max_runs, label=\"max runtime\", linestyle=\":\")\n",
    "plt.plot(ssizes, min_runs, label=\"min runtime\", linestyle=\"--\")\n",
    "plt.plot(ssizes, avg_runs, label=\"avg runtime\", linestyle=\"-.\")\n",
    "# plot a horizontal line of exact runtime\n",
    "plt.plot([ssizes[0],ssizes[3]], [runtime_eps, runtime_eps], label=\"exact\", linestyle=\"-\")\n",
    "# give plot a title and axis labels\n",
    "plt.title(\"Runtime vs Sample Size\")\n",
    "plt.xlabel(\"Sample size\")\n",
    "plt.ylabel(\"Runtime (ms)\")\n",
    "# give both axes a log scale\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "# show legend and plot\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the max, min, and avg error for each sample size\n",
    "plt.plot(ssizes, max_err_runs, label=\"max error\", linestyle=\":\")\n",
    "plt.plot(ssizes, min_err_runs, label=\"min error\", linestyle=\"--\")\n",
    "plt.plot(ssizes, avg_err_runs, label=\"avg error\", linestyle=\"-.\")\n",
    "# divide max eps by 2 for all sample sizes and plot them as a line\n",
    "max_eps_runs2 = [x/2 for x in max_eps_runs]\n",
    "plt.plot(ssizes, max_eps_runs, label=\"max eps/2\", linestyle=\"-\")\n",
    "# give plot a title and axis labels\n",
    "plt.title(\"Error vs epsilon/2\")\n",
    "plt.xlabel(\"Sample size\")\n",
    "plt.ylabel(\"Error\")\n",
    "# give both axes a log scale\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "# show legend and plot\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}